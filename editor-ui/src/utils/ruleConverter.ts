/**
 * VCE Rule Converter Utilities
 *
 * Provides validation, compression, and export utilities for VCE graphs.
 * Graphs are stored directly in the React Flow format (nodes + edges).
 */

import type { Node, Edge } from '@xyflow/react'

// ============================================================================
// Backend Configuration Types
// ============================================================================

export interface BackendConfig {
  name: string
  host: string
  port?: number
  useTls?: boolean
  sniHostname?: string
}

export interface ServiceConfig {
  name: string
  backends: BackendConfig[]
  defaultBackend: string
  configStoreName: string
  logEndpoint?: string
  authSecret?: string
}

// ============================================================================
// Graph Validation
// ============================================================================

/**
 * Validates the graph before export.
 *
 * Minimum valid graph: Request â†’ Backend (pass-through to origin)
 * Action and Condition nodes are optional (for security rules)
 */
export function validateGraph(nodes: Node[], edges: Edge[]): { valid: boolean; errors: string[] } {
  const errors: string[] = []

  // Check for entry point (Request node) - REQUIRED
  const hasRequest = nodes.some(n => n.type === 'request')
  if (!hasRequest) {
    errors.push('Graph must have a Request node (entry point)')
  }

  // Check for at least one Backend node - REQUIRED
  const hasBackend = nodes.some(n => n.type === 'backend')
  if (!hasBackend) {
    errors.push('Graph must have at least one Backend node')
  }

  // Check that Request node has outgoing connections
  const requestNodes = nodes.filter(n => n.type === 'request')
  for (const req of requestNodes) {
    const hasOutgoing = edges.some(e => e.source === req.id)
    if (!hasOutgoing) {
      errors.push('Request node is not connected to any downstream node')
    }
  }

  // Check that Backend nodes have incoming connections
  const backendNodes = nodes.filter(n => n.type === 'backend')
  for (const backend of backendNodes) {
    const hasIncoming = edges.some(e => e.target === backend.id)
    if (!hasIncoming) {
      const name = (backend.data as { name?: string })?.name || backend.id
      errors.push(`Backend "${name}" has no incoming connections`)
    }
  }

  // Check that action nodes (if any) have incoming connections
  const actionNodes = nodes.filter(n => n.type === 'action')
  for (const action of actionNodes) {
    const hasIncoming = edges.some(e => e.target === action.id)
    if (!hasIncoming) {
      errors.push(`Action node ${action.id} has no incoming connections`)
    }
  }

  // Check for disconnected condition nodes (if any)
  const conditionNodes = nodes.filter(n => n.type === 'condition')
  for (const cond of conditionNodes) {
    const hasOutgoing = edges.some(e => e.source === cond.id)
    if (!hasOutgoing) {
      errors.push(`Condition node ${cond.id} is not connected to any downstream node`)
    }
  }

  return { valid: errors.length === 0, errors }
}

// ============================================================================
// Export Functions
// ============================================================================

/**
 * Generates a fastly.toml snippet for the service configuration.
 */
export function generateFastlyToml(config: ServiceConfig): string {
  let toml = `# Visual Compute Engine Configuration
# Generated by VCE Editor

name = "${config.name}"
authors = ["Fastly"]
language = "rust"
manifest_version = 3

[local_server]
`

  // Add backends
  for (const backend of config.backends) {
    toml += `
  [local_server.backends.${backend.name}]
  url = "${backend.useTls ? 'https' : 'http'}://${backend.host}${backend.port ? `:${backend.port}` : ''}"
`
  }

  // Add config stores (auth key is now in the same store)
  toml += `
  [local_server.config_stores.${config.configStoreName}]
  file = "config/${config.configStoreName}.json"
`

  return toml
}

// ============================================================================
// Compression Functions
// ============================================================================

// Config Store limits (from Fastly docs):
// - Key: 256 chars max
// - Value: 8000 UTF-8 chars max
// - Entries: 500 per store (paid accounts)
export const CONFIG_STORE_VALUE_LIMIT = 8000

/**
 * Compresses a string using the browser's CompressionStream API (gzip).
 * Returns base64-encoded compressed data.
 */
export async function compressRules(json: string): Promise<string> {
  const encoder = new TextEncoder()
  const data = encoder.encode(json)

  // Use CompressionStream if available (modern browsers)
  if (typeof CompressionStream !== 'undefined') {
    const cs = new CompressionStream('gzip')
    const writer = cs.writable.getWriter()
    writer.write(data)
    writer.close()

    const compressedChunks: Uint8Array[] = []
    const reader = cs.readable.getReader()

    while (true) {
      const { done, value } = await reader.read()
      if (done) break
      compressedChunks.push(value)
    }

    // Concatenate chunks
    const totalLength = compressedChunks.reduce((sum, chunk) => sum + chunk.length, 0)
    const compressed = new Uint8Array(totalLength)
    let offset = 0
    for (const chunk of compressedChunks) {
      compressed.set(chunk, offset)
      offset += chunk.length
    }

    // Convert to base64
    return btoa(String.fromCharCode(...compressed))
  }

  // Fallback: return uncompressed with marker
  return `raw:${btoa(json)}`
}

/**
 * Generates Config Store content with compression.
 * Stores the graph directly as nodes + edges format.
 */
export async function generateCompressedConfigStoreContent(
  nodes: Node[],
  edges: Edge[]
): Promise<{
  content: Record<string, string>
  stats: {
    originalSize: number
    compressedSize: number
    compressionRatio: number
    fitsInConfigStore: boolean
  }
}> {
  // Store graph directly as nodes + edges
  const graphPayload = { nodes, edges }
  const json = JSON.stringify(graphPayload)
  const originalSize = new TextEncoder().encode(json).length

  const compressed = await compressRules(json)
  const compressedSize = compressed.length

  return {
    content: {
      'rules_packed': compressed
    },
    stats: {
      originalSize,
      compressedSize,
      compressionRatio: Math.round((1 - compressedSize / originalSize) * 100),
      fitsInConfigStore: compressedSize <= CONFIG_STORE_VALUE_LIMIT
    }
  }
}

/**
 * Decompresses base64-encoded gzip data back to a string.
 * Used for testing/preview in the browser.
 */
export async function decompressRules(compressed: string): Promise<string> {
  // Handle raw (uncompressed) fallback
  if (compressed.startsWith('raw:')) {
    return atob(compressed.slice(4))
  }

  // Decode base64
  const binaryString = atob(compressed)
  const bytes = new Uint8Array(binaryString.length)
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i)
  }

  // Decompress using DecompressionStream
  if (typeof DecompressionStream !== 'undefined') {
    const ds = new DecompressionStream('gzip')
    const writer = ds.writable.getWriter()
    writer.write(bytes)
    writer.close()

    const decompressedChunks: Uint8Array[] = []
    const reader = ds.readable.getReader()

    while (true) {
      const { done, value } = await reader.read()
      if (done) break
      decompressedChunks.push(value)
    }

    // Concatenate and decode
    const totalLength = decompressedChunks.reduce((sum, chunk) => sum + chunk.length, 0)
    const decompressed = new Uint8Array(totalLength)
    let offset = 0
    for (const chunk of decompressedChunks) {
      decompressed.set(chunk, offset)
      offset += chunk.length
    }

    return new TextDecoder().decode(decompressed)
  }

  throw new Error('DecompressionStream not available')
}
